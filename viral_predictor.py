import streamlit as st
from scipy import stats
from statsmodels.stats.proportion import proportions_ztest
import numpy as np
import asyncio
import json
import os
import sys
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(dotenv_path=os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env'))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from llms.llm import ViralPredictionLLM
from prompt.content_prediction import get_engagement_prompt
from config.language import TEXTS

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'language' not in st.session_state:
    st.session_state.language = 'en'  # é»˜è®¤è‹±æ–‡

# è¯­è¨€åˆ‡æ¢å‡½æ•°
def toggle_language():
    """åˆ‡æ¢è¯­è¨€"""
    if st.session_state.language == 'en':
        st.session_state.language = 'zh'
    else:
        st.session_state.language = 'en'
    st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ä»¥åº”ç”¨æ–°è¯­è¨€

# è·å–å½“å‰è¯­è¨€çš„æ–‡æœ¬
def get_text(key):
    """è·å–å½“å‰è¯­è¨€çš„æ–‡æœ¬"""
    return TEXTS[st.session_state.language][key]

# è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
def escape_markdown(text):
    """è½¬ä¹‰Markdownä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
    if not isinstance(text, str):
        return text
    return st.markdown(text, escape=True)

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(layout="wide", page_title=get_text("title"))

# è®¾ç½®é¡µé¢æ ·å¼
st.markdown("""
<style>
    .main-header {text-align: center; margin-bottom: 10px;}
    .sub-header {text-align: center; margin-bottom: 30px;}
    .stButton>button {width: 100%;}
    .result-card {
        padding: 20px;
        border-radius: 5px;
        background-color: #f8f9fa;
        margin-bottom: 20px;
        border-left: 5px solid #4CAF50;
    }
    .metric-container {
        padding: 15px;
        border-radius: 5px;
        background-color: #f0f2f6;
        margin-bottom: 10px;
    }
    .metric-title {
        font-weight: bold;
        margin-bottom: 5px;
    }
    .language-toggle {
        position: absolute;
        top: 10px;
        right: 20px;
    }
    .block-container {
        padding-top: 1rem;
        padding-bottom: 0rem;
    }
    .stMarkdown {
        margin-bottom: 0.5rem;
    }
    h4 {
        margin-bottom: 0.3rem;
    }
    .row-widget.stSelectbox, .row-widget.stNumberInput {
        padding-top: 0;
        padding-bottom: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .result-card {
        background-color: #f9f9f9;
        border-radius: 10px;
        padding: 15px;
        margin-bottom: 20px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    .metric-container {
        background-color: #f9f9f9;
        border-radius: 10px;
        padding: 15px;
        margin-bottom: 20px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    .metric-title {
        font-weight: bold;
        margin-bottom: 5px;
    }
    /* è‡ªå®šä¹‰è¯­è¨€æŒ‰é’®æ ·å¼ */
    div.lang-button {
        position: absolute;
        top: 1rem;
        right: 1rem;
        z-index: 999;
    }
    div.lang-button button {
        background-color: #ff5252;
        color: white;
        font-size: 0.8rem;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        border: none;
    }
    /* æ ‡é¢˜å®¹å™¨æ ·å¼ */
    .title-container {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 0.5rem;
    }
    .title-text {
        flex-grow: 1;
        text-align: center;
    }
    .lang-switch-container {
        width: 80px;
    }
    .block-container {
        padding-top: 1rem;
        padding-bottom: 0rem;
    }
    .stMarkdown {
        margin-bottom: 0.5rem;
    }
    h4 {
        margin-bottom: 0.3rem;
    }
    .row-widget.stSelectbox, .row-widget.stNumberInput {
        padding-top: 0;
        padding-bottom: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# åˆ›å»ºæ ‡é¢˜å’Œè¯­è¨€åˆ‡æ¢æŒ‰é’®å¸ƒå±€
st.markdown('<div class="title-container">', unsafe_allow_html=True)
st.markdown(f'<div class="title-text"><h1 class="main-header">{get_text("title")}</h1></div>', unsafe_allow_html=True)

# æ·»åŠ è¯­è¨€åˆ‡æ¢æŒ‰é’®ï¼ˆæ”¾åœ¨æ ‡é¢˜å³ä¾§ï¼‰
st.markdown('<div class="lang-switch-container">', unsafe_allow_html=True)
current_lang = "ä¸­æ–‡" if st.session_state.language == "en" else "EN"
if st.button(f'ğŸŒ {current_lang}', key='lang_toggle'):
    toggle_language()
st.markdown('</div>', unsafe_allow_html=True)

st.markdown('</div>', unsafe_allow_html=True)
st.markdown(f'<h4 class="sub-header">{get_text("subtitle")}</h4>', unsafe_allow_html=True)

# åˆ›å»ºè¾“å…¥è¡¨å•
st.markdown("---")
st.markdown(f"### {get_text('input_section') if 'input_section' in TEXTS[st.session_state.language] else 'å†…å®¹è®¾ç½®'}")

# ç‰ˆæœ¬Aå’Œç‰ˆæœ¬Bçš„è¾“å…¥åŒºåŸŸ
col_a, col_b = st.columns(2)

with col_a:
    st.markdown(f"#### {get_text('version_a')}", help=None)
    version_a = st.text_area(
        label=get_text('version_a'),
        placeholder=get_text('input_placeholder'),
        height=200, 
        key="version_a_input", 
        label_visibility="collapsed"
    )

with col_b:
    st.markdown(f"#### {get_text('version_b')}", help=None)
    version_b = st.text_area(
        label=get_text('version_b'),
        placeholder=get_text('input_placeholder'),
        height=200, 
        key="version_b_input", 
        label_visibility="collapsed"
    )

# å¹³å°å’Œæ¨¡å‹é€‰æ‹©
col_platform, col_provider = st.columns(2)

with col_platform:
    st.markdown(f"#### {get_text('platform')}", help=None)
    platform = st.selectbox(
        label=get_text('platform'),
        options=["Twitter", "Facebook", "Instagram", "LinkedIn", "TikTok"], 
        key="platform_select", 
        label_visibility="collapsed"
    )

with col_provider:
    st.markdown(f"#### {get_text('model_provider')}", help=None)
    provider = st.selectbox(
        label=get_text('model_provider'),
        options=ViralPredictionLLM.get_available_providers(), 
        key="provider_select", 
        label_visibility="collapsed",
        index=ViralPredictionLLM.get_available_providers().index("tencent") if "tencent" in ViralPredictionLLM.get_available_providers() else 0
    )

# æ¨¡å‹é€‰æ‹©å’Œæœ€å¤§ç”¨æˆ·æ•°
col_model, col_users = st.columns(2)

with col_model:
    st.markdown(f"#### {get_text('model')}", help=None)
    available_models = ViralPredictionLLM.get_available_models(provider)
    model = st.selectbox(
        label=get_text('model'),
        options=available_models, 
        key="model_select", 
        label_visibility="collapsed",
        index=available_models.index("deepseek-r1") if "deepseek-r1" in available_models else 0
    )

with col_users:
    st.markdown(f"#### {get_text('max_users')}", help=None)
    max_users = st.number_input(
        label=get_text('max_users'),
        min_value=10, 
        max_value=100, 
        value=20, 
        step=1, 
        key="max_users_input", 
        label_visibility="collapsed"
    )
    standard_batch_size = 5  # æ¯æ‰¹å¤„ç†çš„ç”¨æˆ·æ•°

# é¢„æµ‹æŒ‰é’®
predict_col1, predict_col2, predict_col3 = st.columns([1, 1, 1])
with predict_col2:
    predict_button = st.button(get_text("predict"), use_container_width=True)

# æ·»åŠ é—´éš™
st.markdown("<div style='margin-bottom: 30px;'></div>", unsafe_allow_html=True)

# å›¾è¡¨æ•°æ®
chart_data = {
    "engagement_a": [0],
    "engagement_b": [0],
    "users": [0]
}

async def get_prediction(prompt, llm_client):
    """ä½¿ç”¨LLMå®¢æˆ·ç«¯è·å–é¢„æµ‹ç»“æœ"""
    return await llm_client.predict_engagement(prompt)

async def main():
    if predict_button:
        # åˆå§‹åŒ–è®¡æ•°å™¨
        users = 0
        like_a = comment_a = share_a = quote_a = total_a = 0
        like_b = comment_b = share_b = quote_b = total_b = 0

        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        try:
            llm_client = ViralPredictionLLM(provider=provider, model=model)
            st.info(get_text("using_model").format(provider, model))
        except Exception as e:
            st.error(get_text("init_model_failed").format(str(e)))
            return

        # è·å–å½“å‰è¯­è¨€çš„æç¤ºè¯æ¨¡æ¿
        prompt_template = get_engagement_prompt(st.session_state.language)
        
        # åˆ›å»ºæç¤ºè¯
        prompt_a = prompt_template.format(platform=platform, content=version_a)
        prompt_b = prompt_template.format(platform=platform, content=version_b)

        progress_bar = st.progress(0)
        
        while users < max_users:
            # æ¯æ¬¡é¢„æµ‹5ä¸ªç”¨æˆ·ï¼ˆæˆ–å‰©ä½™çš„ç”¨æˆ·æ•°ï¼‰
            batch_size = min(standard_batch_size, max_users - users)
            predictions_a = []
            predictions_b = []
            
            # å¹¶è¡Œè·å–å¤šä¸ªç”¨æˆ·çš„é¢„æµ‹
            tasks_a = [get_prediction(prompt_a, llm_client) for _ in range(batch_size)]
            tasks_b = [get_prediction(prompt_b, llm_client) for _ in range(batch_size)]
            
            predictions_a = await asyncio.gather(*tasks_a)
            predictions_b = await asyncio.gather(*tasks_b)
            
            # å¤„ç†è¿™æ‰¹é¢„æµ‹ç»“æœ
            for pred_a, pred_b in zip(predictions_a, predictions_b):
                users += 1
                
                like_a += pred_a["like"]
                comment_a += pred_a["comment"]
                share_a += pred_a["share"]
                quote_a += pred_a["quote"]
                total_a = like_a + comment_a + share_a + quote_a

                like_b += pred_b["like"]
                comment_b += pred_b["comment"]
                share_b += pred_b["share"]
                quote_b += pred_b["quote"]
                total_b = like_b + comment_b + share_b + quote_b
                
                # æ›´æ–°å›¾è¡¨æ•°æ®
                chart_data["engagement_a"].append(total_a)
                chart_data["engagement_b"].append(total_b)
                chart_data["users"].append(users)
                
                # æ›´æ–°è¿›åº¦æ¡
                progress_bar.progress(users / max_users)
        
        # æ˜¾ç¤ºç»“æœ
        st.success(get_text("prediction_complete").format(users))
        st.markdown("---")
        
        # æ˜¾ç¤ºç´¯è®¡äº’åŠ¨å›¾è¡¨
        st.subheader(get_text('cumulative_engagement'))
        
        chart_df = {
            get_text("users"): chart_data["users"][1:],
            f"{get_text('version')} A": chart_data["engagement_a"][1:],
            f"{get_text('version')} B": chart_data["engagement_b"][1:]
        }
        
        st.line_chart(chart_df, x=get_text("users"))
        
        # æ˜¾ç¤ºç»Ÿè®¡ç½®ä¿¡åº¦
        st.subheader(get_text('statistical_confidence'))
        
        # åˆ›å»ºç»“æœå¡ç‰‡ - ä½¿ç”¨st.container()æ›¿ä»£HTML div
        with st.container():
            # ä½¿ç”¨expanderç»„ä»¶ä»£æ›¿è‡ªå®šä¹‰HTML
            with st.expander(get_text("total_engagement"), expanded=True):
                # æ˜¾ç¤ºæ€»äº’åŠ¨é‡ç»“æœ
                winner, confidence = calc_confidence(users, total_a, total_b)
                if confidence > 0:
                    if winner == "A":
                        st.success(f"{get_text('better_version').format(winner, confidence)}")
                    else:
                        st.info(f"{get_text('better_version').format(winner, confidence)}")
                else:
                    st.write(f"{get_text('no_difference')}")
        
        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            with st.expander(get_text("likes"), expanded=True):
                st.write(f"A: {like_a} | B: {like_b}")
                winner, confidence = calc_confidence(users, like_a, like_b)
                if confidence > 0:
                    st.write(f"{get_text('better_version').format(winner, confidence)}")
                else:
                    st.write(f"{get_text('no_difference')}")
        
        with col2:
            with st.expander(get_text("comments"), expanded=True):
                st.write(f"A: {comment_a} | B: {comment_b}")
                winner, confidence = calc_confidence(users, comment_a, comment_b)
                if confidence > 0:
                    st.write(f"{get_text('better_version').format(winner, confidence)}")
                else:
                    st.write(f"{get_text('no_difference')}")
        
        with col3:
            with st.expander(get_text("shares"), expanded=True):
                st.write(f"A: {share_a} | B: {share_b}")
                winner, confidence = calc_confidence(users, share_a, share_b)
                if confidence > 0:
                    st.write(f"{get_text('better_version').format(winner, confidence)}")
                else:
                    st.write(f"{get_text('no_difference')}")
        
        with col4:
            with st.expander(get_text("quotes"), expanded=True):
                st.write(f"A: {quote_a} | B: {quote_b}")
                winner, confidence = calc_confidence(users, quote_a, quote_b)
                if confidence > 0:
                    st.write(f"{get_text('better_version').format(winner, confidence)}")
                else:
                    st.write(f"{get_text('no_difference')}")

def calc_confidence(users, vote_a, vote_b):
    if vote_a == 0 and vote_b == 0:
        return "-", 0.0
    
    if vote_a == 0:
        return "B", 100.0
    if vote_b == 0:
        return "A", 100.0
    
    try:
        if vote_a >= vote_b:
            z_stat, vote_confidence_a = proportions_ztest(
                count=[vote_a, vote_b],
                nobs=[users, users],
                alternative='larger'
            )
            vote_confidence_a = (1 - vote_confidence_a) * 100
            return "A", vote_confidence_a if not np.isnan(vote_confidence_a) else 50.0
        else:
            z_stat, vote_confidence_b = proportions_ztest(
                count=[vote_b, vote_a],
                nobs=[users, users],
                alternative='larger'
            )
            vote_confidence_b = (1 - vote_confidence_b) * 100
            return "B", vote_confidence_b if not np.isnan(vote_confidence_b) else 50.0
    except:
        return "-", 0.0

if __name__ == "__main__":
    # è¿è¡Œä¸»åº”ç”¨ç¨‹åº
    asyncio.run(main())
